# Parameters to setup experiment.
experiment:
  # Unique experiment identifier
  id: planes_Res800Lrgb4Lden4_ficus # debug-lego200 # DTU
  # Experiment logs will be stored at "logdir"/"id"
  logdir: /tigress/yb6751/projects/NeuralMFSR/logs
  # Seed for random number generators (for repeatability).
  randomseed: 0 # 34  # 8239
  # Number of training iterations.
  train_iters: 750050
  # Number of training iterations after which to validate.
  validate_every: 50
  # Number of training iterations after which to checkpoint.
  save_every: 5000
  # Number of training iterations after which to print progress.
  print_every: 100

# Dataset parameters.
dataset:
  # Base directory of dataset.
  # type: DTU # DTU,synt
  root: /tigress/yb6751/projects/NeuralMFSR/cache/nerf_synthetic
  # root: /tigress/yb6751/datasets/rs_dtu_4
  dir:
    # train: ['chair','drums','ficus','hotdog','lego','materials','mic','ship']
    train: ficus
  # Optionally, provide a path to the pre-cached dataset dir. This
  # overrides the other dataset options.
  cachedir: cache/legocache200
  # For the Blender datasets (synthetic), optionally return images
  # at half the original resolution of 800 x 800, to save space.
  half_res: True
  # Stride (include one per "testskip" images in the dataset).
  # downsampling_factor: 4 # downsampling factor for the downsampling experiment
  testskip: 10
  # Do not use NDC (normalized device coordinates). Usually True for
  # synthetic (Blender) datasets.
  no_ndc: True
  # Near clip plane (clip all depth values closer than this threshold).
  near: 2
  # Far clip plane (clip all depth values farther than this threshold).
  far: 6

# Model parameters.
models:
  # Coarse model.
  coarse:
    # Name of the torch.nn.Module class that implements the model.
    type: TwoDimPlanesModel
    # Plane side size. Integer or a list of integers to match different scenes.
    plane_resolutions: 800 #64 #32
    # Plane side size for view-direction plane. Can be a list like plane_resolutions.
    # viewdir_plane_resolution: 32
    # Planes interpolation method (default to bilinear):
    plane_interp: bilinear # bicubic # bilinear
    # Number of layers in the density decoder.
    dec_density_layers: 4
    # Number of layers in the rgb decoder.
    dec_rgb_layers: 4
    # dec_channels: 256
    # num_plane_channels: 256
    # What is the input to the rgb decoder, apart from view directions (if used)
    rgb_dec_input:  projections # projections, features
    # proj_combination: concat
    # Whether to align values of -1 and 1 with the actual grid corners when interpolating. If False, these values correspond to the center of corner array values, making the interpolation more resolution dependent.
    align_corners: False
    # Number of hidden units in each layer of the MLP (multi-layer
    # perceptron).
    # hidden_size: 256
    # Add a skip connection once in a while. Note: This parameter
    # won't take affect unless num_layers > skip_connect_every.
    # skip_connect_every: 3
    # Additionally use viewing directions as input.
    use_viewdirs: True
  fine:
    # Name of the torch.nn.Module class that implements the model.
    # type: use_same
    type: TwoDimPlanesModel
    # Plane side size:
    # plane_resolutions: 128
    # # Number of layers in the density decoder.
    # dec_density_layers: 2
    # # Number of layers in the rgb decoder.
    # dec_rgb_layers: 2
    # Share the planes with the coarse model:
    use_coarse_planes: True
    # # Additionally use viewing directions as input.
    # use_viewdirs: False
# Optimizer params.
optimizer:
  # Name of the torch.optim class used for optimization.
  type: Adam
  # Learning rate.
  lr: 5.0E-3

# NeRF parameters.
nerf:
  # Use viewing directions as input, in addition to the X, Y, Z coordinates.
  use_viewdirs: True
  # # Encoding function for position (X, Y, Z).
  # encode_position_fn: None
  # # Encoding function for ray direction (theta, phi).
  # encode_direction_fn: None
  train:
    # Number of random rays to retain from each image.
    # These sampled rays are used for training, and the others are discarded.
    num_random_rays: 4096  # 32 * 32 * 4
    # Size of each chunk (rays are batched into "chunks" and passed through
    # the network)
    chunksize: 131072  # 131072  # 1024 * 32
    # Whether or not to perturb the sampled depth values.
    perturb: True
    # Number of depth samples per ray for the coarse network.
    num_coarse: 64
    # Number of depth samples per ray for the fine network.
    num_fine: 64
    # Whether to render models using a white background.
    white_background: False
    # Standard deviation of noise to be added to the radiance field when
    # performing volume rendering.
    radiance_field_noise_std: 0.2
    # Sample linearly in disparity space, as opposed to in depth space.
    lindisp: False
  # Validation-specific parameters.
  validation:
    # Number of random rays to retain from each image.
    # These sampled rays are used for training, and the others are discarded.
    chunksize: 131072   # 1024 * 32
    # Whether or not to perturb the sampled depth values.
    perturb: False
    # Number of depth samples per ray for the coarse network.
    num_coarse: 64
    # Number of depth samples per ray for the fine network.
    num_fine: 64
    # Whether to render models using a white background.
    white_background: False
    # Standard deviation of noise to be added to the radiance field when
    # performing volume rendering.
    radiance_field_noise_std: 0.
    # Sample linearly in disparity space, as opposed to in depth space.
    lindisp: False
