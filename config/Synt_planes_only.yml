# Parameters to setup experiment.
experiment:
  # Unique experiment identifier
  # id: planes_only_blurrySTD2
  # id: planes_only_258recovery
  # id: planesOnly_fromOther4NoPaper453K_paper4noised5_0
  id: planesOnly_fromNoDetach579K_paper4_8xLR
  # Experiment logs will be stored at "logdir"/"id"
  logdir: /scratch/gpfs/yb6751/projects/VolumetricEnhance/logs
  # Seed for random number generators (for repeatability).
  randomseed: 0 # 34  # 8239
  # Number of training iterations.
  train_iters: 750000
  # Evaluation round frequency:
  validate_every: [0.1,5000] # [Desired portion of evaluation time, compared to training time,Max training iterations between evaluation rounds]
  # Checkpoint saving frequency:
  save_every: 10.0 # Minutes (Use floating point numbers)
  # Number of training iterations after which to print progress:
  print_every: 100

# Dataset parameters.
dataset:
  # Per dataset type configurations:
  synt: # Synthetic scenes, from the NeRF dataset or using the same configuration
    root: /scratch/gpfs/yb6751/datasets/Synthetic
    # Near clip plane (clip all depth values closer than this threshold).
    near: 2
    # Far clip plane (clip all depth values farther than this threshold).
    far:  6
    # Do not use NDC (normalized device coordinates). Usually True for
    # synthetic (Blender) datasets.
    no_ndc: True
  llff: # Real world scenes from NeRF:
    root: /scratch/gpfs/yb6751/datasets/LLFF
    # Near clip plane (clip all depth values closer than this threshold).
    near: 0
    # Far clip plane (clip all depth values farther than this threshold).
    far:  1
    # Do not use NDC (normalized device coordinates). Usually True for
    # synthetic (Blender) datasets.
    no_ndc: False
    # If set, adding test views by interpolating camera poses, to allow rendering smoother high FPS video sequences:
    # min_eval_frames:  200
  max_scenes_eval:  2 # If set, using at most this number of evaluation scenes in evaluation rounds:
  # prob_assigned2scene_groups: False # (Default: True) When True, the probability value reflects the chance of sampling A (any) SCENE IN THE GROUP, and not the probabiliy of sampling any specific scene.
  dir:
    train:
      # Training scenes: 
      # Parameter convention:
      #   downsampling_factor,pos_feature_plane_resolution,viewdir_feature_plane_resoution,dataset_type (default:'synt'),relative probability (default:1): [scene names]
      # Adding suffix "##<integer>" to scene name allows training multiple independent feature plane sets to the same scene. E.g. ['lego','ship','lego##1','lego##2']
      # LR scenes (training and some of evaluation):
      8,200,32:   ['mic##2','ship##2','chair##2','lego##2',]
    val:
      # Evaluation scenes (Should not overlap with training scenes):
      # Use the same parameter convention as in training scenes, without sampling probability
      2,800,32:   ['mic##2','ship##2','chair##2','lego##2',] #'ficus##1','materials##1','hotdog##1','drums##1'
  testskip: 10 # Stride for synthetic scenes: Include one evaluation image per "testskip" images in the dataset.
  llffhold: 2 # For real scenes: Number of training images to hold out for evaluation

# Model parameters.
models:
  # Path to pre-trained model checkpoint to resume (if set):
  path: /scratch/gpfs/yb6751/projects/VolumetricEnhance/logs/E2E_Synt_Res25Sc200_21Sc800_32_LR100_400_noDetach_Lean_other4NoPaper4_0 copy1459K
  init_scenes_hack: True

# Optimizer params.
optimizer:
  # Name of the torch.optim class used for optimization.
  type: Adam
  # Learning rate.
  planes_lr: 4.E-3

# NeRF parameters.
nerf:
  # Use viewing directions as input, in addition to the X, Y, Z coordinates.
  use_viewdirs: True
  # Normalize elevation and azimuth angle ranges to the range observed across training image frames
  # adjust_elevation_range: 1 # Default: False
  # adjust_azimuth_range: True # Default: False
  train: # Training-specific parameters:
    # Which modules to train:
    what: ['LR_planes',]
    # Number of random rays to retain from each image. These sampled rays are used for training, while the rest are discarded:
    num_random_rays: 4096 #3072
    # Size of each chunk (rays are batched into "chunks" and passed through the network):
    chunksize: 131072
    # Store and load plane parameters using hard drive to facilitate simultaneously training on many scenes with limited GPU memory:
    store_planes:
      # buffer_size:  10 # Generally there is not much sense in using a buffer size here, since training of feature planes for different scenes is independent, so an alternative would be to use multiple training runs with fewer scenes each, to meet the memory limitation.
      steps_per_buffer: 5 # Number of training iterations before re-drawing a new set of scenes
    # Whether or not to perturb the sampled depth values along each ray:
    perturb: True
    # Number of depth samples per ray for the coarse network:
    num_coarse: 64
    # Number of depth samples per ray for the fine network:
    num_fine: 64
    # Whether to render models using a white background:
    white_background: False
    # Standard deviation of noise to be added to the radiance field when performing volume rendering.
    radiance_field_noise_std: 0.2
    # Sample linearly in disparity space, as opposed to in depth space.
    lindisp: False
  validation:   # Validation-specific parameters:
    chunksize: 131072
    # Whether or not to perturb the sampled depth values:
    perturb: False
    # Number of depth samples per ray for the coarse network:
    num_coarse: 64
    # Number of depth samples per ray for the fine network:
    num_fine: 64
    # Whether to render models using a white background:
    white_background: False
    # Standard deviation of noise to be added to the radiance field when performing volume rendering:
    radiance_field_noise_std: 0.
    # Sample linearly in disparity space, as opposed to in depth space.
    lindisp: False
super_resolution:
  # lr: 5.E-5
  # training:
  #   loss: fine # fine,coarse,both
  apply_2_coarse: False #True # False
  # Super-resolve view-directions plane as well, or only positional planes:
  SR_viewdir: False
  # input_normalization:  True
  # consistency_loss_w: 0 #1 #0.001
  # plane_loss_w:  0 #1
  # Add Gaussian noise to SR input, with STD relative to the plane's STD:
  # sr_input_noise: 0.1
  # sr_output_noise:  1
  # rendering_loss: 0
  # plane_dropout:  0.5
  # plane_resize_mode:  bicubic
  # model:
  # #   # path: /scratch/gpfs/yb6751/projects/VolumetricEnhance/logs/E2E_Synt_Res266Sc200_258Sc800_32_LR100_400_SRrecField55_PZerMean1_1
    # path: /scratch/gpfs/yb6751/projects/VolumetricEnhance/logs/E2E_Synt_Res25Sc200_21Sc800_32_LR100_400_noDetach_Lean_other4NoPaper4_0_copy453K
    # type: None
    # hidden_size: 256 #128 #256
    # n_blocks: 32

